{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujHhwdAGvRRs"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U pymupdf llama-index-core llama-index-llms-llama-cpp llama-index-embeddings-huggingface llama-index-retrievers-bm25 langchain langchain-openai sentence-transformers google-generativeai\n",
        "!apt-get install -y libgl1-mesa-glx\n",
        "!pip install llama-index-llms-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76PZXHvavCTj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import fitz\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from getpass import getpass\n",
        "from collections import Counter\n",
        "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.response_synthesizers import CompactAndRefine\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.llama_cpp import LlamaCPP\n",
        "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
        "from llama_index.core.postprocessor import LLMRerank\n",
        "from llama_index.core.schema import QueryBundle, NodeWithScore\n",
        "from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from llama_index.core import VectorStoreIndex, Document\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "\n",
        "# Verify CUDA availability\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe88wkeksb3h"
      },
      "outputs": [],
      "source": [
        "# 2. Document Upload & Setup\n",
        "\n",
        "# Upload PDF documents\n",
        "uploaded = files.upload()\n",
        "doc_paths = {\n",
        "    \"Unknown 1\": list(uploaded.keys())[0],\n",
        "    \"Unknown 2\": list(uploaded.keys())[1],\n",
        "    \"Unknown 3\": list(uploaded.keys())[2],\n",
        "    \"Unknown 4\": list(uploaded.keys())[3],\n",
        "}\n",
        "\n",
        "# Extract text from uploaded PDFs\n",
        "doc_texts = {}\n",
        "for i, (doc_type, filename) in enumerate(doc_paths.items()):\n",
        "    with fitz.open(filename) as doc:\n",
        "        text = \"\\n\".join([page.get_text() for page in doc])\n",
        "        doc_texts[f\"Doc-{i+1}\"] = text\n",
        "    print(f\"Extracted {len(text.split())} words from {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA3eiLJtseXP"
      },
      "outputs": [],
      "source": [
        "# 3. Document Classification Components\n",
        "\n",
        "# %%\n",
        "# Set API keys\n",
        "os.environ['OPENAI_API_KEY'] = getpass(\"Enter OpenAI API key: \")\n",
        "os.environ['GOOGLE_API_KEY'] = getpass(\"Enter Google API key: \")\n",
        "\n",
        "def prepare_document_for_classification(text):\n",
        "    # Normalize text\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Get document length\n",
        "    doc_length = len(text)\n",
        "\n",
        "    # Extract first, middle, and last portions\n",
        "    first_part = text[:min(500, doc_length)]\n",
        "    middle_start = max(0, doc_length // 2 - 250)\n",
        "    middle_part = text[middle_start:middle_start + min(500, doc_length - middle_start)]\n",
        "    last_start = max(0, doc_length - 500)\n",
        "    last_part = text[last_start:]\n",
        "\n",
        "    # Extract structural elements\n",
        "    headers = re.findall(r'(?:^|\\n)([A-Z\\s]{5,50})(?:\\n|$)', text)\n",
        "    headers = headers[:10]  # Limit to first 10 headers\n",
        "\n",
        "    tables = re.findall(r'\\n\\|.*\\|.*\\|\\n', text)\n",
        "    table_count = len(tables)\n",
        "\n",
        "    dates = re.findall(r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b', text)\n",
        "    amounts = re.findall(r'\\$\\s*\\d+(?:,\\d{3})*(?:\\.\\d{2})?', text)\n",
        "    names = re.findall(r'\\b([A-Z][a-z]+ [A-Z][a-z]+)\\b', text)\n",
        "\n",
        "    mortgage_keywords = ['mortgage', 'loan', 'interest', 'principal', 'amortization', 'lender', 'borrower', 'payment', 'contract', 'agreement', 'payslip', 'salary', 'income']\n",
        "    keywords_found = [word for word in mortgage_keywords if word.lower() in text.lower()]\n",
        "\n",
        "    word_freq = Counter(text.lower().split())\n",
        "    top_words = dict(word_freq.most_common(10))\n",
        "\n",
        "    return {\n",
        "        \"first_part\": first_part,\n",
        "        \"middle_part\": middle_part,\n",
        "        \"last_part\": last_part,\n",
        "        \"total_length\": doc_length,\n",
        "        \"potential_headers\": \"\\n\".join(headers),\n",
        "        \"table_count\": table_count,\n",
        "        \"dates\": dates,\n",
        "        \"amounts\": amounts,\n",
        "        \"names\": names,\n",
        "        \"keywords\": keywords_found,\n",
        "        \"top_words\": top_words\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1kGm5UJuKhH"
      },
      "outputs": [],
      "source": [
        "def classify_document(text, llm):\n",
        "    doc_info = prepare_document_for_classification(text)\n",
        "\n",
        "    categories = [\n",
        "        \"Bank Statement\", \"Pay Slip\", \"Appraisal Report\", \"Loan Agreement\",\n",
        "        \"Mortgage Contract\", \"Credit Report\", \"Employment Verification\",\n",
        "        \"Tax Return\", \"Insurance Policy\", \"Title Report\", \"Unknown\"\n",
        "    ]\n",
        "\n",
        "    prompt = f\"\"\"You are a document classification expert. Classify this document into one of these categories:\n",
        "    {', '.join(categories[:-1])} or {categories[-1]}\n",
        "\n",
        "    Here's information extracted from the document:\n",
        "\n",
        "    DOCUMENT START EXCERPT:\n",
        "    {doc_info['first_part']}\n",
        "    DOCUMENT START EXCERPT END\n",
        "\n",
        "    DOCUMENT MIDDLE EXCERPT:\n",
        "    {doc_info['middle_part']}\n",
        "    DOCUMENT MIDDLE EXCERPT END\n",
        "\n",
        "    DOCUMENT END EXCERPT:\n",
        "    {doc_info['last_part']}\n",
        "    DOCUMENT END EXCERPT END\n",
        "\n",
        "    Total document length: {doc_info['total_length']} characters\n",
        "\n",
        "    Additional Information:\n",
        "    - Potential Headers: {doc_info['potential_headers']}\n",
        "    - Number of Tables: {doc_info['table_count']}\n",
        "    - Dates Found: {', '.join(doc_info['dates']) if doc_info['dates'] else 'None'}\n",
        "    - Amounts Found: {', '.join(doc_info['amounts']) if doc_info['amounts'] else 'None'}\n",
        "    - Names Found: {', '.join(doc_info['names']) if doc_info['names'] else 'None'}\n",
        "    - Keywords: {', '.join(doc_info['keywords']) if doc_info['keywords'] else 'None'}\n",
        "    - Top 10 Words: {', '.join([f'{k}: {v}' for k, v in doc_info['top_words'].items()])}\n",
        "\n",
        "    IMPORTANT INSTRUCTION: Your response must be EXACTLY ONE of these options:\n",
        "    {', '.join(categories)}\n",
        "\n",
        "    Do not include any explanation, reasoning, or additional text. Respond with ONLY the category name.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.complete(prompt)\n",
        "    raw_response = response.text.strip()\n",
        "\n",
        "    if raw_response in categories:\n",
        "        return raw_response\n",
        "\n",
        "    for category in categories:\n",
        "        if category.lower() in raw_response.lower():\n",
        "            return category\n",
        "\n",
        "    words = raw_response.lower().split()\n",
        "    keyword_map = {\n",
        "        \"Bank Statement\": ['bank', 'statement', 'account', 'transaction'],\n",
        "        \"Pay Slip\": ['pay', 'slip', 'salary', 'income', 'wage'],\n",
        "        \"Appraisal Report\": ['appraisal', 'property', 'valuation', 'assessment'],\n",
        "        \"Loan Agreement\": ['loan', 'agreement', 'borrower', 'lender'],\n",
        "        \"Mortgage Contract\": ['mortgage', 'contract', 'deed', 'lien'],\n",
        "        \"Credit Report\": ['credit', 'report', 'score', 'history'],\n",
        "        \"Employment Verification\": ['employment', 'verification', 'job', 'employer'],\n",
        "        \"Tax Return\": ['tax', 'return', 'irs', 'income'],\n",
        "        \"Insurance Policy\": ['insurance', 'policy', 'coverage', 'premium'],\n",
        "        \"Title Report\": ['title', 'report', 'ownership', 'lien']\n",
        "    }\n",
        "\n",
        "    for category, keywords in keyword_map.items():\n",
        "        if any(kw in words for kw in keywords) or any(kw in doc_info['keywords'] for kw in keywords):\n",
        "            return category\n",
        "\n",
        "    for keyword in doc_info['keywords']:\n",
        "        for category, keywords in keyword_map.items():\n",
        "            if keyword in keywords:\n",
        "                return category\n",
        "\n",
        "    return \"Unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FlPTaqIsh27"
      },
      "outputs": [],
      "source": [
        "# 4. Query Processing Components\n",
        "\n",
        "# Query rewriter setup\n",
        "re_write_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gpt-4o\",\n",
        "    max_tokens=4000,\n",
        "    api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "\n",
        "query_rewrite_template = \"\"\"You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system.\n",
        "Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n",
        "\n",
        "Original query: {original_query}\n",
        "\n",
        "Rewritten query:\"\"\"\n",
        "\n",
        "query_rewrite_prompt = PromptTemplate(\n",
        "    input_variables=[\"original_query\"],\n",
        "    template=query_rewrite_template\n",
        ")\n",
        "\n",
        "query_rewriter = query_rewrite_prompt | re_write_llm\n",
        "\n",
        "def rewrite_query(original_query):\n",
        "    \"\"\"\n",
        "    Rewrite the original query to improve retrieval.\n",
        "\n",
        "    Args:\n",
        "    original_query (str): The original user query\n",
        "\n",
        "    Returns:\n",
        "    str: The rewritten query\n",
        "    \"\"\"\n",
        "    response = query_rewriter.invoke(original_query)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUYRA0G1usaD"
      },
      "outputs": [],
      "source": [
        "def route_query(query, llm, classified_docs):\n",
        "    # Expanded list of categories for mortgage-related documents\n",
        "    categories = [\n",
        "        \"Bank Statement\", \"Pay Slip\", \"Appraisal Report\", \"Loan Agreement\",\n",
        "        \"Mortgage Contract\", \"Credit Report\", \"Employment Verification\",\n",
        "        \"Tax Return\", \"Insurance Policy\", \"Title Report\", \"Unknown\"\n",
        "    ]\n",
        "\n",
        "    # Check which document type the query is related to\n",
        "    prompt = f\"\"\"\n",
        "    Classify the following question into one of these categories:\n",
        "    {', '.join(categories[:-1])} or {categories[-1]}\n",
        "\n",
        "    IMPORTANT INSTRUCTION: Your response must be EXACTLY ONE of these options:\n",
        "    {', '.join(categories)}\n",
        "\n",
        "    Do not include any explanation, reasoning, or additional text. Respond with ONLY the category name.\n",
        "\n",
        "    Query: {query}\n",
        "    \"\"\"\n",
        "\n",
        "    doc_type = llm.complete(prompt).text.strip()\n",
        "\n",
        "    raw_response = doc_type\n",
        "\n",
        "    # Post-process to extract just the category name\n",
        "    if raw_response in categories:\n",
        "        doc_type = raw_response\n",
        "\n",
        "    # If not, look for the category within the response\n",
        "    for category in categories:\n",
        "        if category.lower() in raw_response.lower():\n",
        "            doc_type = category\n",
        "\n",
        "    # If still no match, return the closest match based on keywords\n",
        "    words = raw_response.lower().split()\n",
        "    keyword_map = {\n",
        "        \"Bank Statement\": ['bank', 'statement', 'account', 'transaction'],\n",
        "        \"Pay Slip\": ['pay', 'slip', 'salary', 'income', 'wage'],\n",
        "        \"Appraisal Report\": ['appraisal', 'property', 'valuation', 'assessment'],\n",
        "        \"Loan Agreement\": ['loan', 'agreement', 'borrower', 'lender'],\n",
        "        \"Contract\": ['agreement', 'contract', 'mortgage', 'deed', 'lien'],\n",
        "        \"Credit Report\": ['credit', 'report', 'score', 'history'],\n",
        "        \"Employment Verification\": ['employment', 'verification', 'job', 'employer'],\n",
        "        \"Tax Return\": ['tax', 'return', 'irs', 'income'],\n",
        "        \"Insurance Policy\": ['insurance', 'policy', 'coverage', 'premium'],\n",
        "        \"Title Report\": ['title', 'report', 'ownership', 'lien']\n",
        "    }\n",
        "\n",
        "    for category, keywords in keyword_map.items():\n",
        "        if any(kw in words for kw in keywords):\n",
        "            doc_type = category\n",
        "            break\n",
        "    else:\n",
        "        doc_type = \"Unknown\"\n",
        "\n",
        "     # Filter documents based on the determined document type\n",
        "    relevant_docs = [\n",
        "        doc_data[\"document\"] for doc_data in classified_docs.values()\n",
        "        if doc_data[\"doc_type\"] == doc_type\n",
        "    ]\n",
        "\n",
        "    # Debug print to check if any documents were found\n",
        "    print(f\"Number of relevant documents found for query '{query}': {len(relevant_docs)}\")\n",
        "\n",
        "    # Fallback mechanism: If no relevant documents are found, use all documents\n",
        "    if not relevant_docs:\n",
        "        print(\"No relevant documents found. Using all documents as fallback.\")\n",
        "        relevant_docs = [doc_data[\"document\"] for doc_data in classified_docs.values()]\n",
        "\n",
        "    return relevant_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCtGOhqpsj5O"
      },
      "outputs": [],
      "source": [
        "# 5. Retrieval & Ranking Setup\n",
        "\n",
        "# Download model for LlamaCPP\n",
        "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O mistral-7b-instruct.gguf\n",
        "\n",
        "# Initialize models\n",
        "llm = LlamaCPP(\n",
        "    model_path=\"mistral-7b-instruct.gguf\",\n",
        "    temperature=0.0,\n",
        "    max_new_tokens=30,\n",
        "    context_window=4096,\n",
        "    model_kwargs={\"n_gpu_layers\": 1, \"verbose\": False}\n",
        ")\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "def semantic_chunk(docs, embed_model):\n",
        "    \"\"\"Modified to handle LlamaIndex Documents directly\"\"\"\n",
        "    # Create a sentence splitter for initial text splitting\n",
        "    sentence_splitter = SentenceSplitter(chunk_size=512)\n",
        "\n",
        "    # Create a semantic splitter for more meaningful chunks\n",
        "    semantic_splitter = SemanticSplitterNodeParser(\n",
        "        buffer_size=1,\n",
        "        breakpoint_percentile_threshold=95,\n",
        "        embed_model=embed_model\n",
        "    )\n",
        "\n",
        "    nodes = []\n",
        "    for doc in docs:\n",
        "        # Split document into sentences first\n",
        "        split_sentences = sentence_splitter.get_nodes_from_documents([doc])\n",
        "\n",
        "        # Then apply semantic splitting to the sentences\n",
        "        semantic_nodes = semantic_splitter.get_nodes_from_documents(split_sentences)\n",
        "        nodes.extend(semantic_nodes)\n",
        "\n",
        "    print(f\"Number of {docs[0].metadata['doc_type']} nodes after splitting: {len(nodes)}\")\n",
        "    top_k_bm25 = min(3, len(nodes))\n",
        "    return nodes, top_k_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g1jelOUu5Ol"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "class HybridRetriever(BaseRetriever):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vector_retriever,\n",
        "        bm25_retriever,\n",
        "        vector_weight: float = 0.5,\n",
        "        top_k_per_retriever: int = 10,\n",
        "        top_n: int = 10,\n",
        "        dedup_threshold: float = 0.9,\n",
        "    ):\n",
        "        self.vector_retriever = vector_retriever\n",
        "        self.bm25_retriever = bm25_retriever\n",
        "        self.vector_weight = vector_weight\n",
        "        self.top_k_per_retriever = top_k_per_retriever\n",
        "        self.top_n = top_n\n",
        "        self.dedup_threshold = dedup_threshold\n",
        "        super().__init__()\n",
        "\n",
        "    def _normalize_scores(self, nodes: List[NodeWithScore]) -> List[NodeWithScore]:\n",
        "        if not nodes:\n",
        "            return []\n",
        "        scores = [node.score for node in nodes]\n",
        "        min_score, max_score = min(scores), max(scores)\n",
        "        for node in nodes:\n",
        "            if max_score - min_score == 0:\n",
        "                node.score = 0.0\n",
        "            else:\n",
        "                node.score = (node.score - min_score) / (max_score - min_score)\n",
        "        return nodes\n",
        "\n",
        "    def _deduplicate_nodes(self, nodes: List[NodeWithScore]) -> List[NodeWithScore]:\n",
        "        deduped = []\n",
        "        seen_ids = set()\n",
        "        for node in nodes:\n",
        "            if node.node.node_id not in seen_ids:\n",
        "                seen_ids.add(node.node.node_id)\n",
        "                deduped.append(node)\n",
        "        return deduped\n",
        "\n",
        "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "        # Parallel retrieval (example using threading)\n",
        "        import threading\n",
        "        vector_results = []\n",
        "        bm25_results = []\n",
        "\n",
        "        def fetch_vector():\n",
        "            nonlocal vector_results\n",
        "            vector_results = self.vector_retriever.retrieve(query_bundle)[:self.top_k_per_retriever]\n",
        "\n",
        "        def fetch_bm25():\n",
        "            nonlocal bm25_results\n",
        "            bm25_results = self.bm25_retriever.retrieve(query_bundle)[:self.top_k_per_retriever]\n",
        "\n",
        "        t1 = threading.Thread(target=fetch_vector)\n",
        "        t2 = threading.Thread(target=fetch_bm25)\n",
        "        t1.start()\n",
        "        t2.start()\n",
        "        t1.join()\n",
        "        t2.join()\n",
        "\n",
        "        # Normalize and fuse scores\n",
        "        vector_nodes = self._normalize_scores(vector_results)\n",
        "        bm25_nodes = self._normalize_scores(bm25_results)\n",
        "\n",
        "        combined_nodes = []\n",
        "        for node in vector_nodes:\n",
        "            combined_score = self.vector_weight * node.score\n",
        "            combined_nodes.append((node, combined_score))\n",
        "        for node in bm25_nodes:\n",
        "            combined_score = (1 - self.vector_weight) * node.score\n",
        "            combined_nodes.append((node, combined_score))\n",
        "\n",
        "        # Sort by combined score and deduplicate\n",
        "        combined_nodes.sort(key=lambda x: x[1], reverse=True)\n",
        "        deduped_nodes = self._deduplicate_nodes([node for node, _ in combined_nodes])\n",
        "\n",
        "        # Apply final top_n limit\n",
        "        return deduped_nodes[:self.top_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UF4vqHjNsmS3"
      },
      "outputs": [],
      "source": [
        "# 6. Document Classification Execution\n",
        "\n",
        "# Classify documents\n",
        "print(\"CLASSIFYING DOCUMENTS...\")\n",
        "classified_docs = {}\n",
        "for doc_id, text in doc_texts.items():\n",
        "    doc_type = classify_document(text, llm)\n",
        "    classified_docs[doc_id] = {\n",
        "        \"text\": text,\n",
        "        \"doc_type\": doc_type,\n",
        "        \"document\": Document(text=text, metadata={\"doc_type\": doc_type})\n",
        "    }\n",
        "    print(f\"Classified {doc_id} as: {doc_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPEaU_MusoRr"
      },
      "outputs": [],
      "source": [
        "# 7. Query Execution\n",
        "\n",
        "# Process query\n",
        "print(\"\\nPROCESSING QUERY...\")\n",
        "original_query = input(\"Enter your query: \")\n",
        "rewritten_query = rewrite_query(original_query)\n",
        "print(f\"Original: {original_query}\\nRewritten: {rewritten_query}\")\n",
        "\n",
        "# Route query\n",
        "print(\"\\nQUERY ROUTING...\")\n",
        "query_route_results = route_query(rewritten_query, llm, classified_docs)\n",
        "\n",
        "# Prepare retrieval system\n",
        "nodes, top_k_bm25 = semantic_chunk(query_route_results, embed_model)\n",
        "docstore = SimpleDocumentStore()\n",
        "docstore.add_documents(nodes)\n",
        "\n",
        "vector_index = VectorStoreIndex.from_documents(query_route_results, embed_model=embed_model)\n",
        "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5)\n",
        "bm25_retriever = BM25Retriever.from_defaults(docstore=docstore, similarity_top_k=3)\n",
        "\n",
        "hybrid_retriever = HybridRetriever(\n",
        "    vector_retriever=vector_retriever,\n",
        "    bm25_retriever=bm25_retriever\n",
        ")\n",
        "\n",
        "# Final query execution\n",
        "llm = GoogleGenAI(model=\"gemini-1.5-flash\")\n",
        "query_engine = RetrieverQueryEngine.from_args(hybrid_retriever, llm=llm)\n",
        "response = query_engine.query(rewritten_query)\n",
        "\n",
        "print(\"\\nFINAL RESPONSE:\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}